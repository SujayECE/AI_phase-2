	Model – 2 : RandomForest Regression;
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# Upload 'Own AI data.xlsx' in Google Colab before running this cell
# Load the dataset
dataset = pd.read_excel('Own AI data.xlsx')

# Separate features and target variable
x = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

# Split the dataset into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)

# Create and train the Random Forest Regressor model
model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(x_train, y_train)

# Make predictions on the test set
y_pred = model.predict(x_test)

# Calculate Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Mean Absolute Error (MAE):", mae)
print("Root Mean Squared Error (RMSE):", rmse)

# Make a prediction for a new data point
new_data = [[78300, 6, 8, 3, 48050]]
predicted_result = model.predict(new_data)
print("Predicted Price for New Data:", predicted_result)

# Plotting the predicted vs actual prices
plt.scatter(y_test, y_pred, color='blue')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual Prices vs Predicted Prices")
plt.show()



 


	Model – 3 : XG Bosster Regression;
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import xgboost as xgb
import matplotlib.pyplot as plt

# Upload 'Own AI data.xlsx' in Google Colab before running this cell
# Load the dataset
dataset = pd.read_excel('Own AI data.xlsx')

# Separate features and target variable
x = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

# Split the dataset into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)

# Create and train the XGBoost Regressor model
model = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators=100, random_state=0)
model.fit(x_train, y_train)

# Make predictions on the test set
y_pred = model.predict(x_test)

# Calculate Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Mean Absolute Error (MAE):", mae)
print("Root Mean Squared Error (RMSE):", rmse)

# Make a prediction for a new data point
new_data = [[78300, 6, 8, 3, 48050]]
predicted_result = model.predict(np.array(new_data))
print("Predicted Price for New Data:", predicted_result)

# Plotting the predicted vs actual prices
plt.scatter(y_test, y_pred, color='blue')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual Prices vs Predicted Prices")
plt.show()
